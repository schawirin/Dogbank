# =============================================================================
# Ollama - Local LLM Server (Optional)
# =============================================================================
# Local LLM inference server as an alternative to cloud LLM providers
# Can be used by chatbot-service for local AI processing
# =============================================================================

apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: ollama
  namespace: dogbank
  labels:
    app: ollama
    tags.datadoghq.com/env: dogbank
    tags.datadoghq.com/service: ollama
spec:
  serviceName: ollama
  replicas: 1
  selector:
    matchLabels:
      app: ollama
  template:
    metadata:
      labels:
        app: ollama
        tags.datadoghq.com/env: dogbank
        tags.datadoghq.com/service: ollama
      annotations:
        ad.datadoghq.com/ollama.logs: '[{"source": "ollama", "service": "ollama"}]'
    spec:
      containers:
        - name: ollama
          image: ollama/ollama:latest
          ports:
            - containerPort: 11434
              name: http
          env:
            - name: OLLAMA_MODEL
              value: "llama3.2:1b"
            - name: OLLAMA_NUM_PARALLEL
              value: "1"
            - name: OLLAMA_MAX_LOADED_MODELS
              value: "1"
          resources:
            requests:
              memory: "2Gi"
              cpu: "1000m"
            limits:
              memory: "4Gi"
              cpu: "2000m"
          volumeMounts:
            - name: ollama-data
              mountPath: /root/.ollama
          livenessProbe:
            httpGet:
              path: /api/tags
              port: 11434
            initialDelaySeconds: 120
            periodSeconds: 30
            timeoutSeconds: 10
          readinessProbe:
            httpGet:
              path: /api/tags
              port: 11434
            initialDelaySeconds: 60
            periodSeconds: 10
            timeoutSeconds: 5
  volumeClaimTemplates:
    - metadata:
        name: ollama-data
      spec:
        accessModes: ["ReadWriteOnce"]
        resources:
          requests:
            storage: 5Gi

---
apiVersion: v1
kind: Service
metadata:
  name: ollama
  namespace: dogbank
  labels:
    app: ollama
spec:
  type: ClusterIP
  ports:
    - port: 11434
      targetPort: 11434
      protocol: TCP
      name: http
  selector:
    app: ollama
