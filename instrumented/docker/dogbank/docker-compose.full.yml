# =============================================================================
# Docker Compose Full Stack - DogBank com Datadog APM
# =============================================================================
# Este arquivo sobe TUDO: Frontend + Backend + Banco de Dados + Datadog
#
# Servi√ßos inclu√≠dos:
# - PostgreSQL (banco de dados)
# - Redis (cache)
# - Datadog Agent (APM, m√©tricas, logs)
# - Auth Service (autentica√ß√£o)
# - Account Service (contas)
# - Transaction Service (transa√ß√µes PIX)
# - Banco Central Service (valida√ß√£o PIX)
# - Frontend (React + Nginx)
# - Nginx Gateway (proxy reverso)
#
# =============================================================================
# USO:
#   # Configurar API Key do Datadog
#   export DD_API_KEY="sua-api-key-aqui"
#   
#   docker-compose -f docker-compose.full.yml up -d
#
# PARAR TUDO:
#   docker-compose -f docker-compose.full.yml down
#
# LIMPAR TUDO (incluindo dados):
#   docker-compose -f docker-compose.full.yml down -v
#
# VER LOGS:
#   docker-compose -f docker-compose.full.yml logs -f
#
# =============================================================================

services:
  # ===========================================================================
  # üíæ BANCO DE DADOS - PostgreSQL
  # ===========================================================================
  
  postgres:
    image: postgres:15-alpine
    container_name: dogbank-postgres
    environment:
      POSTGRES_DB: dogbank
      POSTGRES_USER: dogbank
      POSTGRES_PASSWORD: dog1234
      PGDATA: /var/lib/postgresql/data/pgdata
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./init-db:/docker-entrypoint-initdb.d:ro
    command:
      - "postgres"
      - "-c"
      - "shared_preload_libraries=pg_stat_statements"
      - "-c"
      - "pg_stat_statements.max=10000"
      - "-c"
      - "pg_stat_statements.track=all"
      - "-c"
      - "track_activity_query_size=4096"
      # Logging configuration for Datadog
      - "-c"
      - "logging_collector=on"
      - "-c"
      - "log_directory=/var/log/postgresql"
      - "-c"
      - "log_filename=postgresql.log"
      - "-c"
      - "log_statement=all"
      - "-c"
      - "log_duration=on"
      - "-c"
      - "log_min_duration_statement=0"
      - "-c"
      - "log_line_prefix=%m [%p] %d %u %a "
      - "-c"
      - "log_connections=on"
      - "-c"
      - "log_disconnections=on"
      - "-c"
      - "log_lock_waits=on"
      - "-c"
      - "log_temp_files=0"
      - "-c"
      - "log_checkpoints=on"
    networks:
      - dogbank-network
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U dogbank -d dogbank"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 30s
    restart: unless-stopped
    labels:
      com.datadoghq.ad.logs: '[{"source": "postgresql", "service": "dogbank-postgres", "log_processing_rules": [{"type": "multi_line", "name": "log_start_with_date", "pattern": "^\\d{4}-\\d{2}-\\d{2}"}]}]'
      com.datadoghq.tags.env: "dogbank"
      com.datadoghq.tags.service: "dogbank-postgres"

  # ===========================================================================
  # üî¥ CACHE - Redis
  # ===========================================================================
  
  redis:
    image: redis:7-alpine
    container_name: dogbank-redis
    command: redis-server --appendonly yes --maxmemory 128mb --maxmemory-policy allkeys-lru
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    networks:
      - dogbank-network
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5
    restart: unless-stopped
    labels:
      com.datadoghq.ad.check_names: '["redisdb"]'
      com.datadoghq.ad.init_configs: '[{}]'
      com.datadoghq.ad.instances: '[{"host":"%%host%%", "port":"6379"}]'
      com.datadoghq.ad.logs: '[{"source": "redis", "service": "dogbank-redis"}]'

  # ===========================================================================
  # üì® KAFKA - Message Queue for PIX Transactions (KRaft Mode - No Zookeeper!)
  # ===========================================================================
  # Using Official Apache Kafka image in KRaft mode - much lighter and faster!
  # No Zookeeper dependency = less memory, faster boot, simpler architecture
  
  kafka:
    image: apache/kafka:latest
    container_name: dogbank-kafka
    ports:
      - "9092:9092"
      - "29092:29092"
    environment:
      # KRaft mode configuration (official Apache Kafka image)
      KAFKA_NODE_ID: 1
      KAFKA_PROCESS_ROLES: broker,controller
      KAFKA_CONTROLLER_QUORUM_VOTERS: 1@kafka:9093
      KAFKA_CONTROLLER_LISTENER_NAMES: CONTROLLER
      # Listeners
      KAFKA_LISTENERS: PLAINTEXT://:29092,CONTROLLER://:9093,EXTERNAL://:9092
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:29092,EXTERNAL://localhost:9092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT,EXTERNAL:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      # Topic settings
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"
      # Performance tuning for demo
      KAFKA_NUM_PARTITIONS: 3
      KAFKA_LOG_RETENTION_HOURS: 24
      # Cluster ID for KRaft
      CLUSTER_ID: dogbank-kafka-cluster-001
    volumes:
      - kafka_data:/var/lib/kafka/data
    networks:
      - dogbank-network
    healthcheck:
      test: ["CMD-SHELL", "/opt/kafka/bin/kafka-topics.sh --bootstrap-server localhost:29092 --list || exit 1"]
      interval: 10s
      timeout: 10s
      retries: 10
      start_period: 45s
    restart: unless-stopped
    labels:
      com.datadoghq.ad.logs: '[{"source": "kafka", "service": "dogbank-kafka"}]'

  # Kafka topic initialization
  kafka-init:
    image: apache/kafka:latest
    container_name: dogbank-kafka-init
    depends_on:
      kafka:
        condition: service_healthy
    entrypoint: ["/bin/sh", "-c"]
    command: |
      "
      echo 'Creating Kafka topics...'
      /opt/kafka/bin/kafka-topics.sh --bootstrap-server kafka:29092 --create --if-not-exists --topic pix-transactions --partitions 3 --replication-factor 1
      /opt/kafka/bin/kafka-topics.sh --bootstrap-server kafka:29092 --create --if-not-exists --topic pix-results --partitions 3 --replication-factor 1
      /opt/kafka/bin/kafka-topics.sh --bootstrap-server kafka:29092 --create --if-not-exists --topic pix-notifications --partitions 3 --replication-factor 1
      /opt/kafka/bin/kafka-topics.sh --bootstrap-server kafka:29092 --create --if-not-exists --topic pix-dlq --partitions 1 --replication-factor 1
      echo 'Topics created:'
      /opt/kafka/bin/kafka-topics.sh --bootstrap-server kafka:29092 --list
      "
    networks:
      - dogbank-network

  # ===========================================================================
  # üê∞ RABBITMQ - Message Queue for FIFO Processing
  # ===========================================================================
  # RabbitMQ handles transactional processing with guaranteed order (FIFO)
  # while Kafka handles event sourcing and analytics
  
  rabbitmq:
    image: rabbitmq:3.12-management-alpine
    container_name: dogbank-rabbitmq
    hostname: rabbitmq
    environment:
      RABBITMQ_DEFAULT_USER: dogbank
      RABBITMQ_DEFAULT_PASS: dog1234
      RABBITMQ_DEFAULT_VHOST: dogbank
      # Enable plugins
      RABBITMQ_PLUGINS: "rabbitmq_management rabbitmq_prometheus"
    ports:
      - "5672:5672"    # AMQP
      - "15672:15672"  # Management UI
      - "15692:15692"  # Prometheus metrics
    volumes:
      - rabbitmq_data:/var/lib/rabbitmq
      - ./rabbitmq/definitions.json:/etc/rabbitmq/definitions.json:ro
      - ./rabbitmq/rabbitmq.conf:/etc/rabbitmq/rabbitmq.conf:ro
    networks:
      - dogbank-network
    healthcheck:
      test: ["CMD", "rabbitmq-diagnostics", "-q", "ping"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 30s
    restart: unless-stopped
    labels:
      com.datadoghq.ad.check_names: '["rabbitmq"]'
      com.datadoghq.ad.init_configs: '[{}]'
      com.datadoghq.ad.instances: '[{"rabbitmq_api_url": "http://%%host%%:15672/api/", "username": "dogbank", "password": "dog1234"}]'
      com.datadoghq.ad.logs: '[{"source": "rabbitmq", "service": "dogbank-rabbitmq"}]'



  # ===========================================================================
  # üêï DATADOG AGENT
  # ===========================================================================
  
  datadog-agent:
    image: gcr.io/datadoghq/agent:latest
    container_name: datadog-agent
    environment:
      # API Key (obrigat√≥rio)
      DD_API_KEY: ${DD_API_KEY:-}
      # Site do Datadog (us1.datadoghq.com para US, datadoghq.eu para EU)
      DD_SITE: ${DD_SITE:-datadoghq.com}
      # Hostname
      DD_HOSTNAME: dogbank-docker
      # APM
      DD_APM_ENABLED: "true"
      DD_APM_NON_LOCAL_TRAFFIC: "true"
      # Logs
      DD_LOGS_ENABLED: "true"
      DD_LOGS_CONFIG_CONTAINER_COLLECT_ALL: "true"
      # Process monitoring
      DD_PROCESS_AGENT_ENABLED: "true"
      # Container monitoring
      DD_CONTAINER_EXCLUDE: "name:datadog-agent"
      # Tags
      DD_TAGS: "env:dogbank project:dogbank"
      # Dogstatsd
      DD_DOGSTATSD_NON_LOCAL_TRAFFIC: "true"
      # Database Monitoring (DBM)
      DD_DBM_ENABLED: "true"
      # Data Streams Monitoring (DSM)
      DD_DATA_STREAMS_ENABLED: "true"
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock:ro
      - /proc/:/host/proc/:ro
      - /sys/fs/cgroup/:/host/sys/fs/cgroup:ro
      - /var/lib/docker/containers:/var/lib/docker/containers:ro
      - ./datadog/conf.d/postgres.d/conf.yaml:/etc/datadog-agent/conf.d/postgres.d/conf.yaml:ro
      - ./datadog/conf.d/kafka.d/conf.yaml:/etc/datadog-agent/conf.d/kafka.d/conf.yaml:ro
      - ./datadog/conf.d/rabbitmq.d/conf.yaml:/etc/datadog-agent/conf.d/rabbitmq.d/conf.yaml:ro
    ports:
      - "8126:8126"  # APM traces
      - "8125:8125/udp"  # DogStatsD
    networks:
      - dogbank-network
    depends_on:
      postgres:
        condition: service_healthy
    restart: unless-stopped

  # ===========================================================================
  # üèõÔ∏è BANCO CENTRAL SERVICE
  # ===========================================================================
  
  bancocentral-service:
    build:
      context: .
      dockerfile: dockerfiles/Dockerfile.bancocentral
    container_name: bancocentral-service
    environment:
      SPRING_PROFILES_ACTIVE: docker
      SPRING_DATASOURCE_URL: jdbc:postgresql://postgres:5432/dogbank
      SPRING_DATASOURCE_USERNAME: dogbank
      SPRING_DATASOURCE_PASSWORD: dog1234
      SERVER_PORT: 8085
      # Datadog APM - Full tracing enabled
      DD_AGENT_HOST: datadog-agent
      DD_TRACE_AGENT_PORT: 8126
      DD_SERVICE: bancocentral-service
      DD_ENV: dogbank
      DD_VERSION: "1.0.0"
      DD_LOGS_INJECTION: "true"
      DD_PROFILING_ENABLED: "true"
      DD_TRACE_SAMPLE_RATE: "1"
      DD_RUNTIME_METRICS_ENABLED: "true"
    volumes:
      - ./dd-java-agent.jar:/app/dd-java-agent.jar:ro
    depends_on:
      postgres:
        condition: service_healthy
      datadog-agent:
        condition: service_started
    networks:
      - dogbank-network
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:8085/actuator/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 90s
    restart: unless-stopped
    labels:
      com.datadoghq.ad.logs: '[{"source": "java", "service": "bancocentral-service"}]'
      com.datadoghq.tags.env: "dogbank"
      com.datadoghq.tags.service: "bancocentral-service"
      com.datadoghq.tags.version: "1.0.0"

  # ===========================================================================
  # üîë AUTH SERVICE
  # ===========================================================================
  
  auth-service:
    build:
      context: .
      dockerfile: dockerfiles/Dockerfile.auth
    container_name: auth-service
    environment:
      SPRING_PROFILES_ACTIVE: docker
      SPRING_DATASOURCE_URL: jdbc:postgresql://postgres:5432/dogbank
      SPRING_DATASOURCE_USERNAME: dogbank
      SPRING_DATASOURCE_PASSWORD: dog1234
      SPRING_REDIS_HOST: redis
      SPRING_REDIS_PORT: 6379
      SERVER_PORT: 8088
      JWT_SECRET: dogbank-secret-key-change-in-production
      JWT_EXPIRATION: 86400000
      # Datadog
      DD_AGENT_HOST: datadog-agent
      DD_SERVICE: auth-service
      DD_ENV: dogbank
      DD_VERSION: "1.0.0"
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
      datadog-agent:
        condition: service_started
    networks:
      - dogbank-network
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:8088/actuator/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 90s
    restart: unless-stopped
    labels:
      com.datadoghq.ad.logs: '[{"source": "java", "service": "auth-service"}]'

  # ===========================================================================
  # üí≥ ACCOUNT SERVICE
  # ===========================================================================
  
  account-service:
    build:
      context: .
      dockerfile: dockerfiles/Dockerfile.account
    container_name: account-service
    environment:
      SPRING_PROFILES_ACTIVE: docker
      SPRING_DATASOURCE_URL: jdbc:postgresql://postgres:5432/dogbank
      SPRING_DATASOURCE_USERNAME: dogbank
      SPRING_DATASOURCE_PASSWORD: dog1234
      SERVER_PORT: 8089
      # Datadog
      DD_AGENT_HOST: datadog-agent
      DD_SERVICE: account-service
      DD_ENV: dogbank
      DD_VERSION: "1.0.0"
    depends_on:
      postgres:
        condition: service_healthy
      auth-service:
        condition: service_healthy
      datadog-agent:
        condition: service_started
    networks:
      - dogbank-network
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:8089/actuator/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 90s
    restart: unless-stopped
    labels:
      com.datadoghq.ad.logs: '[{"source": "java", "service": "account-service"}]'

  # ===========================================================================
  # üí∏ TRANSACTION SERVICE
  # ===========================================================================
  
  transaction-service:
    build:
      context: .
      dockerfile: dockerfiles/Dockerfile.transaction
    container_name: transaction-service
    environment:
      SPRING_PROFILES_ACTIVE: docker
      SPRING_DATASOURCE_URL: jdbc:postgresql://postgres:5432/dogbank
      SPRING_DATASOURCE_USERNAME: dogbank
      SPRING_DATASOURCE_PASSWORD: dog1234
      SERVER_PORT: 8084
      BANCOCENTRAL_API_URL: http://bancocentral-service:8085/api/bancocentral
      ACCOUNT_SERVICE_URL: http://account-service:8089
      # Kafka
      KAFKA_ENABLED: "true"
      KAFKA_BOOTSTRAP_SERVERS: kafka:29092
      # RabbitMQ
      RABBITMQ_ENABLED: "true"
      RABBITMQ_HOST: rabbitmq
      RABBITMQ_PORT: 5672
      RABBITMQ_USER: dogbank
      RABBITMQ_PASS: dog1234
      RABBITMQ_VHOST: dogbank
      # Datadog APM + DSM - Full tracing for end-to-end visibility
      DD_AGENT_HOST: datadog-agent
      DD_TRACE_AGENT_PORT: 8126
      DD_SERVICE: transaction-service
      DD_ENV: dogbank
      DD_VERSION: "1.0.0"
      DD_LOGS_INJECTION: "true"
      DD_PROFILING_ENABLED: "true"
      DD_TRACE_SAMPLE_RATE: "1"
      DD_RUNTIME_METRICS_ENABLED: "true"
      # Data Streams Monitoring - Kafka & RabbitMQ visibility
      DD_DATA_STREAMS_ENABLED: "true"
      DD_TRACE_KAFKA_ENABLED: "true"
      DD_TRACE_RABBITMQ_ENABLED: "true"
      DD_TRACE_REMOVE_INTEGRATION_SERVICE_NAMES_ENABLED: "true"
    volumes:
      - ./dd-java-agent.jar:/app/dd-java-agent.jar:ro
    depends_on:
      postgres:
        condition: service_healthy
      bancocentral-service:
        condition: service_healthy
      account-service:
        condition: service_healthy
      kafka:
        condition: service_healthy
      rabbitmq:
        condition: service_healthy
      datadog-agent:
        condition: service_started
    networks:
      - dogbank-network
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:8084/actuator/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 90s
    restart: unless-stopped
    labels:
      com.datadoghq.ad.logs: '[{"source": "java", "service": "transaction-service"}]'


  # ===========================================================================
  # ü§ñ CHATBOT SERVICE - Assistente Virtual com LLM
  # ===========================================================================
  # ‚ö†Ô∏è VULNER√ÅVEL A PROMPT INJECTION - PROPOSITAL PARA DEMO
  # ===========================================================================
  
  chatbot-service:
    build:
      context: ./chatbot-python
      dockerfile: Dockerfile
    container_name: chatbot-service
    environment:
      # =================================================================
      # LLM Configuration - Choose your provider:
      # =================================================================
      # GROQ - Default, super fast inference, free tier
      OPENAI_API_KEY: ${OPENAI_API_KEY:-}  # Get from https://console.groq.com/
      OPENAI_API_BASE_URL: ${OPENAI_API_BASE_URL:-https://api.groq.com/openai/v1}
      OPENAI_MODEL: ${OPENAI_MODEL:-llama-3.1-8b-instant}  # llama-3.1-8b-instant, mixtral-8x7b-32768
      # 
      # Alternative providers (uncomment to use):
      # QWEN (Alibaba) - Free tier available
      # OPENAI_API_BASE_URL: https://dashscope.aliyuncs.com/compatible-mode/v1
      # OPENAI_MODEL: qwen-turbo
      #
      # OPENAI - Original
      # OPENAI_API_BASE_URL: https://api.openai.com/v1
      # OPENAI_MODEL: gpt-4o-mini
      #
      # OLLAMA - Local (requires ollama service)
      # OPENAI_API_BASE_URL: http://ollama:11434/v1
      # OPENAI_MODEL: llama3.2:1b
      # =================================================================
      # Service URLs
      ACCOUNT_SERVICE_URL: http://account-service:8089
      TRANSACTION_SERVICE_URL: http://transaction-service:8087
      AUTH_SERVICE_URL: http://auth-service:8088
      # Datadog APM
      DD_AGENT_HOST: datadog-agent
      DD_TRACE_AGENT_PORT: 8126
      DD_ENV: dogbank
      DD_SERVICE: chatbot-service
      DD_VERSION: "2.0.0"
      DD_LOGS_INJECTION: "true"
      DD_PROFILING_ENABLED: "true"
      # Datadog LLM Observability
      DD_LLMOBS_ENABLED: "1"
      DD_LLMOBS_ML_APP: "dogbot-assistant"
      DD_LLMOBS_AGENTLESS_ENABLED: "false"
      DD_SITE: ${DD_SITE:-datadoghq.com}
      # Data Streams Monitoring (for future Kafka/RabbitMQ integration)
      DD_DATA_STREAMS_ENABLED: "true"
    depends_on:
      datadog-agent:
        condition: service_healthy
      # Uncomment if using Ollama:
      # ollama:
      #   condition: service_healthy
    networks:
      - dogbank-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8083/api/chatbot/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s
    restart: unless-stopped
    labels:
      com.datadoghq.ad.logs: '[{"source": "python", "service": "chatbot-service"}]'


  # ===========================================================================
  # ü§ñ OLLAMA - Local LLM Server
  # ===========================================================================
  
  ollama:
    image: ollama/ollama:latest
    container_name: dogbank-ollama
    entrypoint: ["/bin/bash", "/entrypoint.sh"]
    ports:
      - "11434:11434"
    volumes:
      - ollama_data:/root/.ollama
      - ./ollama-entrypoint.sh:/entrypoint.sh:ro
    environment:
      # Model to auto-pull on startup
      OLLAMA_MODEL: ${OLLAMA_MODEL:-llama3.2:1b}
      # Minimal memory usage
      OLLAMA_NUM_PARALLEL: 1
      OLLAMA_MAX_LOADED_MODELS: 1
    networks:
      - dogbank-network
    healthcheck:
      # Check if model is loaded (not just server running)
      test: ["CMD-SHELL", "curl -s http://localhost:11434/api/tags | grep -q llama || curl -s http://localhost:11434/api/tags | grep -q phi || curl -s http://localhost:11434/api/tags | grep -q qwen || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 10
      start_period: 120s
    restart: unless-stopped
    labels:
      com.datadoghq.ad.logs: '[{"source": "ollama", "service": "ollama"}]'
    # Uncomment for GPU support (NVIDIA)
    # deploy:
    #   resources:
    #     reservations:
    #       devices:
    #         - driver: nvidia
    #           count: 1
    #           capabilities: [gpu]


  # ===========================================================================
  # üîÑ PIX WORKER - Kafka Consumer
  # ===========================================================================
  
  pix-worker:
    build:
      context: ./pix-worker-module
      dockerfile: Dockerfile
    container_name: dogbank-pix-worker
    depends_on:
      kafka:
        condition: service_healthy
      postgres:
        condition: service_healthy
      bancocentral-service:
        condition: service_healthy
    environment:
      # Kafka
      KAFKA_BOOTSTRAP_SERVERS: kafka:29092
      # Database
      SPRING_DATASOURCE_URL: jdbc:postgresql://postgres:5432/dogbank
      SPRING_DATASOURCE_USERNAME: dogbank
      SPRING_DATASOURCE_PASSWORD: dog1234
      # External services
      BANCOCENTRAL_SERVICE_URL: http://bancocentral-service:8085
      # Datadog
      DD_AGENT_HOST: datadog-agent
      DD_TRACE_AGENT_PORT: 8126
      DD_SERVICE: pix-worker
      DD_ENV: dogbank
      DD_VERSION: "1.0.0"
      DD_LOGS_INJECTION: "true"
      DD_PROFILING_ENABLED: "true"
      DD_TRACE_KAFKA_ENABLED: "true"
      DD_API_KEY: ${DD_API_KEY:-}
      DD_METRICS_ENABLED: "true"
      # Data Streams Monitoring
      DD_DATA_STREAMS_ENABLED: "true"
      DD_TRACE_REMOVE_INTEGRATION_SERVICE_NAMES_ENABLED: "true"
    volumes:
      - ./dd-java-agent.jar:/app/dd-java-agent.jar:ro
    networks:
      - dogbank-network
    restart: unless-stopped
    labels:
      com.datadoghq.ad.logs: '[{"source": "java", "service": "pix-worker"}]'
      com.datadoghq.tags.env: "dogbank"
      com.datadoghq.tags.service: "pix-worker"
      com.datadoghq.tags.version: "1.0.0"


  # ===========================================================================
  # üîç FRAUD DETECTION SERVICE - RabbitMQ Consumer
  # ===========================================================================
  # Analyzes PIX transactions for fraud using ML simulation
  # Consumes from RabbitMQ pix.fraud queue with FIFO guarantee
  
  fraud-detection-service:
    build:
      context: ./fraud-detection-module
      dockerfile: Dockerfile
    container_name: dogbank-fraud-detection
    depends_on:
      rabbitmq:
        condition: service_healthy
      datadog-agent:
        condition: service_started
    environment:
      # RabbitMQ
      RABBITMQ_HOST: rabbitmq
      RABBITMQ_PORT: 5672
      RABBITMQ_USER: dogbank
      RABBITMQ_PASS: dog1234
      RABBITMQ_VHOST: dogbank
      # Datadog APM + DSM - Full tracing for RabbitMQ visibility
      DD_AGENT_HOST: datadog-agent
      DD_TRACE_AGENT_PORT: 8126
      DD_SERVICE: fraud-detection-service
      DD_ENV: dogbank
      DD_VERSION: "1.0.0"
      DD_LOGS_INJECTION: "true"
      DD_PROFILING_ENABLED: "true"
      DD_TRACE_SAMPLE_RATE: "1"
      DD_RUNTIME_METRICS_ENABLED: "true"
      # Data Streams Monitoring - RabbitMQ visibility in Service Map
      DD_DATA_STREAMS_ENABLED: "true"
      DD_TRACE_RABBITMQ_ENABLED: "true"
      DD_TRACE_REMOVE_INTEGRATION_SERVICE_NAMES_ENABLED: "true"
    volumes:
      - ./dd-java-agent.jar:/app/dd-java-agent.jar:ro
    networks:
      - dogbank-network
    restart: unless-stopped
    labels:
      com.datadoghq.ad.logs: '[{"source": "java", "service": "fraud-detection-service"}]'
      com.datadoghq.tags.env: "dogbank"
      com.datadoghq.tags.service: "fraud-detection-service"
      com.datadoghq.tags.version: "1.0.0"

  # ===========================================================================
  # üåê FRONTEND - React + Nginx
  # ===========================================================================
  
  frontend:
    build:
      context: ../dogbank-frontend
      dockerfile: Dockerfile
    container_name: dogbank-frontend
    networks:
      - dogbank-network
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:80"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    restart: unless-stopped
    labels:
      com.datadoghq.ad.logs: '[{"source": "nginx", "service": "dogbank-frontend"}]'

  # ===========================================================================
  # üö™ NGINX GATEWAY - Proxy Reverso
  # ===========================================================================
  
  nginx:
    image: nginx:stable-alpine
    container_name: dogbank-nginx
    ports:
      - "80:80"
    volumes:
      - ./nginx/nginx-gateway.conf:/etc/nginx/conf.d/default.conf:ro
    depends_on:
      - frontend
      - auth-service
      - account-service
      - transaction-service
      - bancocentral-service
    networks:
      - dogbank-network
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:80/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    restart: unless-stopped
    labels:
      com.datadoghq.ad.check_names: '["nginx"]'
      com.datadoghq.ad.init_configs: '[{}]'
      com.datadoghq.ad.instances: '[{"nginx_status_url": "http://%%host%%:80/nginx_status"}]'
      com.datadoghq.ad.logs: '[{"source": "nginx", "service": "dogbank-nginx"}]'

  # ===========================================================================
  # ü§ñ LOAD GENERATOR - Gerador de Carga Autom√°tico
  # ===========================================================================
  # Simula transa√ß√µes PIX autom√°ticas para gerar dados de observabilidade
  # Cen√°rios: normal, erro R$ 100, COAF (>= R$ 50k), saldo insuficiente
  
  load-generator:
    build:
      context: ./load-generator
      dockerfile: Dockerfile
    container_name: dogbank-load-generator
    depends_on:
      auth-service:
        condition: service_healthy
      transaction-service:
        condition: service_healthy
      account-service:
        condition: service_healthy
    environment:
      AUTH_SERVICE_URL: http://auth-service:8088
      TRANSACTION_SERVICE_URL: http://transaction-service:8084
      ACCOUNT_SERVICE_URL: http://account-service:8089
      # Intervalo entre transa√ß√µes (segundos)
      MIN_INTERVAL: "3"
      MAX_INTERVAL: "8"
      # Probabilidades de cen√°rios
      PROB_NORMAL: "0.55"       # 55% transa√ß√µes normais
      PROB_ERROR_100: "0.20"    # 20% erro R$ 100 (cen√°rio espec√≠fico)
      PROB_COAF: "0.10"         # 10% COAF (>= R$ 50k)
      PROB_INSUFFICIENT: "0.15" # 15% saldo insuficiente
    networks:
      - dogbank-network
    restart: unless-stopped
    labels:
      com.datadoghq.ad.logs: '[{"source": "python", "service": "load-generator"}]'
      com.datadoghq.tags.env: "dogbank"
      com.datadoghq.tags.service: "load-generator"

# =============================================================================
# üåê NETWORKS
# =============================================================================

networks:
  dogbank-network:
    driver: bridge

# =============================================================================
# üíæ VOLUMES
# =============================================================================

volumes:
  postgres_data:
    driver: local
  redis_data:
    driver: local
  ollama_data:
    driver: local
  rabbitmq_data:
    driver: local
  kafka_data:
    driver: local
